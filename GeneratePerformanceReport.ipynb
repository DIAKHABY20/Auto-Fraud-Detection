{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9ZfNWRQa9otOkmVfCGCOi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OWL4fvy0_J3",
        "outputId": "3b6ace18-a581-428f-8c95-a50a795f5f23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mistralai in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: httpx<1,>=0.25 in /usr/local/lib/python3.10/dist-packages (from mistralai) (0.27.0)\n",
            "Requirement already satisfied: orjson<3.11,>=3.9.10 in /usr/local/lib/python3.10/dist-packages (from mistralai) (3.10.6)\n",
            "Requirement already satisfied: pydantic<3,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from mistralai) (2.8.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.25->mistralai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.25->mistralai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.25->mistralai) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.25->mistralai) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.25->mistralai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.25->mistralai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.5.2->mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.5.2->mistralai) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.5.2->mistralai) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.25->mistralai) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install mistralai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mistralai.client import MistralClient\n",
        "from mistralai.models.chat_completion import ChatMessage"
      ],
      "metadata": {
        "id": "oKLfnGYX10ja"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Générer un rapport sur les performances des modèles de détection de fraude suivants :\n",
        "\n",
        "1. **ResNet50**\n",
        "   - **Accuracy**: 0.666667\n",
        "   - **Precision**: 0.666667\n",
        "   - **Recall**: 1.0\n",
        "   - **F1-Score**: 0.8\n",
        "\n",
        "2. **InceptionV3**\n",
        "   - **Accuracy**: 0.666667\n",
        "   - **Precision**: 0.666667\n",
        "   - **Recall**: 1.0\n",
        "   - **F1-Score**: 0.8\n",
        "\n",
        "3. **VGG16**\n",
        "   - **Accuracy**: 0.666667\n",
        "   - **Precision**: 0.666667\n",
        "   - **Recall**: 1.0\n",
        "   - **F1-Score**: 0.8\n",
        "\n",
        "4. **MobileNetV2**\n",
        "   - **Accuracy**: 0.666667\n",
        "   - **Precision**: 0.666667\n",
        "   - **Recall**: 1.0\n",
        "   - **F1-Score**: 0.8\n",
        "\n",
        "5. **EfficientNetB0**\n",
        "   - **Accuracy**: 0.666667\n",
        "   - **Precision**: 0.666667\n",
        "   - **Recall**: 1.0\n",
        "   - **F1-Score**: 0.8\n",
        "\n",
        "Analysez les résultats et fournissez des recommandations pour l'amélioration des performances des modèles. Mentionnez également les observations intéressantes à partir des images testées, y compris toute tendance ou anomalie notée dans les résultats de classification.\n",
        "\n",
        "De plus, voici les résultats d'autres modèles de détection de fraude utilisant différentes techniques d'apprentissage automatique :\n",
        "\n",
        "1. **SVM**\n",
        "   - **Accuracy**: 0.962791\n",
        "   - **Precision**: 0.989880\n",
        "   - **Recall**: 0.935142\n",
        "   - **F1-Score**: 0.961733\n",
        "\n",
        "2. **KNN**\n",
        "   - **Accuracy**: 1.000000\n",
        "   - **Precision**: 1.000000\n",
        "   - **Recall**: 1.000000\n",
        "   - **F1-Score**: 1.000000\n",
        "\n",
        "3. **RandomForest**\n",
        "   - **Accuracy**: 0.954953\n",
        "   - **Precision**: 0.923373\n",
        "   - **Recall**: 0.992248\n",
        "   - **F1-Score**: 0.956572\n",
        "\n",
        "4. **LightGBM**\n",
        "   - **Accuracy**: 0.977562\n",
        "   - **Precision**: 0.992013\n",
        "   - **Recall**: 0.962877\n",
        "   - **F1-Score**: 0.977228\n",
        "\n",
        "5. **CatBoost**\n",
        "   - **Accuracy**: 0.900689\n",
        "   - **Precision**: 0.857296\n",
        "   - **Recall**: 0.961413\n",
        "   - **F1-Score**: 0.906374\n",
        "\n",
        "6. **NaiveBayes**\n",
        "   - **Accuracy**: 0.888415\n",
        "   - **Precision**: 0.975635\n",
        "   - **Recall**: 0.796727\n",
        "   - **F1-Score**: 0.877151\n",
        "\n",
        "7. **DecisionTree**\n",
        "   - **Accuracy**: 0.905383\n",
        "   - **Precision**: 0.881495\n",
        "   - **Recall**: 0.936693\n",
        "   - **F1-Score**: 0.908256\n",
        "\n",
        "8. **AdaBoost**\n",
        "   - **Accuracy**: 0.764212\n",
        "   - **Precision**: 0.692501\n",
        "   - **Recall**: 0.950474\n",
        "   - **F1-Score**: 0.801234\n",
        "\n",
        "9. **LogisticRegression**\n",
        "   - **Accuracy**: 0.966236\n",
        "   - **Precision**: 0.997427\n",
        "   - **Recall**: 0.934884\n",
        "   - **F1-Score**: 0.965143\n",
        "\n",
        "10. **XGBoost**\n",
        "    - **Accuracy**: 0.934841\n",
        "    - **Precision**: 0.907170\n",
        "    - **Recall**: 0.968820\n",
        "    - **F1-Score**: 0.936982\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vCArytGGBDwe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
        "model = \"mistral-large-latest\"\n",
        "\n",
        "client = MistralClient(api_key=api_key)\n",
        "\n",
        "chat_response = client.chat(\n",
        "    model=model,\n",
        "    messages=[ChatMessage(role=\"user\", content=prompt)]\n",
        ")\n",
        "\n",
        "\n",
        "report = chat_response.choices[0].message.content\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrMmWVf27Ax8",
        "outputId": "a231ee78-1436-4b3a-f346-6efcdbbd5ce8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Rapport sur les Performances des Modèles de Détection de Fraude\n",
            "\n",
            "## Introduction\n",
            "\n",
            "Ce rapport présente une analyse des performances de divers modèles de détection de fraude, incluant des modèles de réseaux de neurones convolutifs (CNN) et des modèles d'apprentissage automatique traditionnels. Les métriques évaluées incluent l'accuracy, la précision, le recall et le F1-Score.\n",
            "\n",
            "## Performances des Modèles CNN\n",
            "\n",
            "### 1. ResNet50\n",
            "- **Accuracy**: 0.666667\n",
            "- **Precision**: 0.666667\n",
            "- **Recall**: 1.0\n",
            "- **F1-Score**: 0.8\n",
            "\n",
            "### 2. InceptionV3\n",
            "- **Accuracy**: 0.666667\n",
            "- **Precision**: 0.666667\n",
            "- **Recall**: 1.0\n",
            "- **F1-Score**: 0.8\n",
            "\n",
            "### 3. VGG16\n",
            "- **Accuracy**: 0.666667\n",
            "- **Precision**: 0.666667\n",
            "- **Recall**: 1.0\n",
            "- **F1-Score**: 0.8\n",
            "\n",
            "### 4. MobileNetV2\n",
            "- **Accuracy**: 0.666667\n",
            "- **Precision**: 0.666667\n",
            "- **Recall**: 1.0\n",
            "- **F1-Score**: 0.8\n",
            "\n",
            "### 5. EfficientNetB0\n",
            "- **Accuracy**: 0.666667\n",
            "- **Precision**: 0.666667\n",
            "- **Recall**: 1.0\n",
            "- **F1-Score**: 0.8\n",
            "\n",
            "### Observations\n",
            "\n",
            "Tous les modèles CNN présentent des performances identiques avec une accuracy de 0.666667, une précision de 0.666667, un recall de 1.0 et un F1-Score de 0.8. Cette uniformité des résultats suggère que les modèles pourraient être limités par des facteurs communs, tels que la qualité des données d'entraînement ou la complexité des caractéristiques de fraude.\n",
            "\n",
            "## Performances des Modèles d'Apprentissage Automatique\n",
            "\n",
            "### 1. SVM\n",
            "- **Accuracy**: 0.962791\n",
            "- **Precision**: 0.989880\n",
            "- **Recall**: 0.935142\n",
            "- **F1-Score**: 0.961733\n",
            "\n",
            "### 2. KNN\n",
            "- **Accuracy**: 1.000000\n",
            "- **Precision**: 1.000000\n",
            "- **Recall**: 1.000000\n",
            "- **F1-Score**: 1.000000\n",
            "\n",
            "### 3. RandomForest\n",
            "- **Accuracy**: 0.954953\n",
            "- **Precision**: 0.923373\n",
            "- **Recall**: 0.992248\n",
            "- **F1-Score**: 0.956572\n",
            "\n",
            "### 4. LightGBM\n",
            "- **Accuracy**: 0.977562\n",
            "- **Precision**: 0.992013\n",
            "- **Recall**: 0.962877\n",
            "- **F1-Score**: 0.977228\n",
            "\n",
            "### 5. CatBoost\n",
            "- **Accuracy**: 0.900689\n",
            "- **Precision**: 0.857296\n",
            "- **Recall**: 0.961413\n",
            "- **F1-Score**: 0.906374\n",
            "\n",
            "### 6. NaiveBayes\n",
            "- **Accuracy**: 0.888415\n",
            "- **Precision**: 0.975635\n",
            "- **Recall**: 0.796727\n",
            "- **F1-Score**: 0.877151\n",
            "\n",
            "### 7. DecisionTree\n",
            "- **Accuracy**: 0.905383\n",
            "- **Precision**: 0.881495\n",
            "- **Recall**: 0.936693\n",
            "- **F1-Score**: 0.908256\n",
            "\n",
            "### 8. AdaBoost\n",
            "- **Accuracy**: 0.764212\n",
            "- **Precision**: 0.692501\n",
            "- **Recall**: 0.950474\n",
            "- **F1-Score**: 0.801234\n",
            "\n",
            "### 9. LogisticRegression\n",
            "- **Accuracy**: 0.966236\n",
            "- **Precision**: 0.997427\n",
            "- **Recall**: 0.934884\n",
            "- **F1-Score**: 0.965143\n",
            "\n",
            "### 10. XGBoost\n",
            "- **Accuracy**: 0.934841\n",
            "- **Precision**: 0.907170\n",
            "- **Recall**: 0.968820\n",
            "- **F1-Score**: 0.936982\n",
            "\n",
            "### Observations\n",
            "\n",
            "Les modèles d'apprentissage automatique traditionnels montrent des performances nettement supérieures à celles des modèles CNN. Le modèle KNN affiche des performances parfaites, ce qui est inhabituel et pourrait indiquer un surapprentissage ou une évaluation sur des données de test similaires aux données d'entraînement. Les modèles SVM, LightGBM, et LogisticRegression montrent également des performances très élevées.\n",
            "\n",
            "## Recommandations pour l'Amélioration des Performances\n",
            "\n",
            "### Pour les Modèles CNN\n",
            "1. **Augmentation des Données**: Utiliser des techniques d'augmentation des données pour enrichir le jeu de données d'entraînement.\n",
            "2. **Hyperparamètres**: Ajuster les hyperparamètres des modèles pour mieux capturer les caractéristiques de fraude.\n",
            "3. **Ensemble de Modèles**: Combiner les prédictions de plusieurs modèles CNN pour améliorer la performance globale.\n",
            "\n",
            "### Pour les Modèles d'Apprentissage Automatique\n",
            "1. **Validation Croisée**: Utiliser la validation croisée pour éviter le surapprentissage et obtenir une estimation plus fiable des performances.\n",
            "2. **Sélection de Caractéristiques**: Appliquer des techniques de sélection de caractéristiques pour améliorer la qualité des données d'entrée.\n",
            "3. **Ensemble de Modèles**: Combiner les prédictions de plusieurs modèles d'apprentissage automatique pour améliorer la performance globale.\n",
            "\n",
            "## Conclusion\n",
            "\n",
            "Les modèles d'apprentissage automatique traditionnels, en particulier KNN, SVM, LightGBM, et LogisticRegression, montrent des performances supérieures à celles des modèles CNN pour la détection de fraude. Les modèles CNN pourraient bénéficier d'une augmentation des données et d'un ajustement des hyperparamètres. Pour les modèles d'apprentissage automatique, une validation croisée et une sélection de caractéristiques pourraient améliorer encore les performances.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Contenu du rapport\n",
        "markdown_report = report\n",
        "\n",
        "markdown_file_path = \"/content/rapport_performance.md\"\n",
        "with open(markdown_file_path, \"w\") as file:\n",
        "    file.write(markdown_report)\n"
      ],
      "metadata": {
        "id": "OYC1nkVyEM44"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}